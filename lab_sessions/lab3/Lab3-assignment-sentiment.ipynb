{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab3 - Assignment Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright: Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook describes the LAB-3 assignment of the Text Mining course. It is about sentiment analysis.\n",
    "\n",
    "The aims of the assignment are:\n",
    "* Learn how to run a rule-based sentiment analysis module (VADER)\n",
    "* Learn how to run a machine learning sentiment analysis module (Scikit-Learn/ Naive Bayes)\n",
    "* Learn how to run scikit-learn metrics for the quantitative evaluation\n",
    "* Learn how to perform and interpret a quantitative evaluation of the outcomes of the tools (in terms of Precision, Recall, and F<sub>1</sub>)\n",
    "* Learn how to evaluate the results qualitatively (by examining the data) \n",
    "* Get insight into differences between the two applied methods\n",
    "* Get insight into the effects of using linguistic preprocessing\n",
    "* Be able to describe differences between the two methods in terms of their results\n",
    "* Get insight into issues when applying these methods across different  domains\n",
    "\n",
    "In this assignment, you are going to create your own gold standard set from 50 tweets. You will the VADER and scikit-learn classifiers to these tweets and evaluate the results by using evaluation metrics and inspecting the data.\n",
    "\n",
    "We recommend you go through the notebooks in the following order:\n",
    "* **Read the assignment (see below)**\n",
    "* **Lab3.2-Sentiment-analysis-with-VADER.ipynb**\n",
    "* **Lab3.3-Sentiment-analysis.with-scikit-learn.ipynb**\n",
    "* **Answer the questions of the assignment (see below) using the provided notebooks and submit**\n",
    "\n",
    "In this assignment you are asked to perform both quantitative evaluations and error analyses:\n",
    "* a quantitative evaluation concerns the scores (Precision, Recall, and F<sub>1</sub>) provided by scikit's classification_report. It includes the scores per category, as well as micro and macro averages. Discuss whether the scores are balanced or not between the different categories (positive, negative, neutral) and between precision and recall. Discuss the shortcomings (if any) of the classifier based on these scores\n",
    "* an error analysis regarding the misclassifications of the classifier. It involves going through the texts and trying to understand what has gone wrong. It servers to get insight in what could be done to improve the performance of the classifier. Do you observe patterns in misclassifications?  Discuss why these errors are made and propose ways to solve them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits\n",
    "The notebooks in this block have been originally created by [Marten Postma](https://martenpostma.github.io) and [Isa Maks](https://research.vu.nl/en/persons/e-maks). Adaptations were made by [Filip Ilievski](http://ilievski.nl)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: VADER assignments\n",
    "\n",
    "\n",
    "### Preparation (nothing to submit):\n",
    "To be able to answer the VADER questions you need to know how the tool works. \n",
    "* Read more about the VADER tool in [this blog](http://t-redactyl.io/blog/2017/04/using-vader-to-handle-sentiment-analysis-with-social-media-text.html).  \n",
    "* VADER provides 4 scores (positive, negative, neutral, compound). Be sure to understand what they mean and how they are calculated.\n",
    "* VADER uses rules to handle linguistic phenomena such as negation and intensification. Be sure to understand which rules are used, how they work, and why they are important.\n",
    "* VADER makes use of a sentiment lexicon. Have a look at the lexicon. Be sure to understand which information can be found there (lemma?, wordform?, part-of-speech?, polarity value?, word meaning?) What do all scores mean? https://github.com/cjhutto/vaderSentiment/blob/master/vaderSentiment/vader_lexicon.txt) \n",
    "\n",
    "\n",
    "### [3.5 points] Question1:\n",
    "\n",
    "Regard the following sentences and their output as given by VADER. Regard sentences 1 to 7, and explain the outcome **for each sentence**. Take into account both the rules applied by VADER and the lexicon that is used. You will find that some of the results are reasonable, but others are not. Explain what is going wrong or not when correct and incorrect results are produced. \n",
    "\n",
    "```\n",
    "INPUT SENTENCE 1 I love apples\n",
    "VADER OUTPUT {'neg': 0.0, 'neu': 0.192, 'pos': 0.808, 'compound': 0.6369}\n",
    "\n",
    "INPUT SENTENCE 2 I don't love apples\n",
    "VADER OUTPUT {'neg': 0.627, 'neu': 0.373, 'pos': 0.0, 'compound': -0.5216}\n",
    "\n",
    "INPUT SENTENCE 3 I love apples :-)\n",
    "VADER OUTPUT {'neg': 0.0, 'neu': 0.133, 'pos': 0.867, 'compound': 0.7579}\n",
    "\n",
    "INPUT SENTENCE 4 These houses are ruins\n",
    "VADER OUTPUT {'neg': 0.492, 'neu': 0.508, 'pos': 0.0, 'compound': -0.4404}\n",
    "\n",
    "INPUT SENTENCE 5 These houses are certainly not considered ruins\n",
    "VADER OUTPUT {'neg': 0.0, 'neu': 0.51, 'pos': 0.49, 'compound': 0.5867}\n",
    "\n",
    "INPUT SENTENCE 6 He lies in the chair in the garden\n",
    "VADER OUTPUT {'neg': 0.286, 'neu': 0.714, 'pos': 0.0, 'compound': -0.4215}\n",
    "\n",
    "INPUT SENTENCE 7 This house is like any house\n",
    "VADER OUTPUT {'neg': 0.0, 'neu': 0.667, 'pos': 0.333, 'compound': 0.3612}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence 1: 'love' only has positive valence, 'I' and 'apples' are neutral words and the negative score is 0 because there are no negative words. The result is correct.\n",
    "\n",
    "Sentence 2: 'love' has a positive valence, but it sees the negative \"don't\" and flips the love segment into a negative.  'I' and 'apples' are neutral words. The result is correct.\n",
    "\n",
    "Sentence 3: VADER recognises the emoticon ':-)' as a positive valence, alongside 'love'. Similarly to the first sentence, it has a high positive score, but the smiley face gives it a stronger positive valence. The result is correct.\n",
    "\n",
    "Sentence 4: 'ruins' is regarded as a negative word, synonymous with words like 'destroyed', it regards the sentence as negative overall, while the rest are neutral words, hence the high neutral score. The result is correct.\n",
    "\n",
    "Sentence 5: 'ruins' is a negative word, 'not' flips the statement and 'certainly' amplifies the valence. The rest are neutral words. The result is correct.\n",
    "\n",
    "Sentence 6: 'lies' is considered negative, the rest are neutral, hence the big neutral score. The result is incorrect, because VADER did not understand the context of \n",
    "the sentence.\n",
    "\n",
    "Sentence 7: 'like' is regarded as a positive word and increases the overall score, however the result should be neutral, due to the context being a neutral sentence. The compound should be 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Points: 2.5] Exercise 2: Collecting 50 tweets for evaluation\n",
    "Collect 50 tweets. Try to find tweets that are interesting for sentiment analysis, e.g., very positive, neutral, and negative tweets. These could be your own tweets (typed in) or collected from the Twitter stream. If you have trouble accessing Twitter, try to find an existing dataset (on websites like kaggle or huggingface).\n",
    "\n",
    "We will store the tweets in the file **my_tweets.json** (use a text editor to edit).\n",
    "For each tweet, you should insert:\n",
    "* sentiment analysis label: negative | neutral | positive (this you determine yourself, this is not done by a computer)\n",
    "* the text of the tweet\n",
    "* the Tweet-URL\n",
    "\n",
    "from:\n",
    "```\n",
    "    \"1\": {\n",
    "        \"sentiment_label\": \"\",\n",
    "        \"text_of_tweet\": \"\",\n",
    "        \"tweet_url\": \"\",\n",
    "```\n",
    "to:\n",
    "```\n",
    "\"1\": {\n",
    "        \"sentiment_label\": \"positive\",\n",
    "        \"text_of_tweet\": \"All across America people chose to get involved, get engaged and stand up. Each of us can make a difference, and all of us ought to try. So go keep changing the world in 2018.\",\n",
    "        \"tweet_url\" : \"https://twitter.com/BarackObama/status/946775615893655552\",\n",
    "    },\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load your tweets with human annotation in the following way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tweets = json.load(open('my_tweets.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'sentiment_label': 'Neutral', 'text_of_tweet': '_ricardo road movies indies rule  haha', 'tweet_url': ''}\n"
     ]
    }
   ],
   "source": [
    "for id_, tweet_info in my_tweets.items():\n",
    "    print(id_, tweet_info)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5 points] Question 3:\n",
    "\n",
    "Run VADER on your own tweets (see function **run_vader** from notebook **Lab2-Sentiment-analysis-using-VADER.ipynb**). You can use the code snippet below this explanation as a starting point. \n",
    "* [2.5 points] a. Perform a quantitative evaluation. Explain the different scores, and explain which scores are most relevant and why.\n",
    "* [2.5 points] b. Perform an error analysis: select 10 positive, 10 negative and 10 neutral tweets that are not correctly classified and try to understand why. Refer to the VADER-rules and the VADER-lexicon. Of course, if there are less than 10 errors for a category, you only have to check those. For example, if there are only 5 errors for positive tweets, you just describe those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_output_to_label(vader_output):\n",
    "    \"\"\"\n",
    "    map vader output e.g.,\n",
    "    {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.4215}\n",
    "    to one of the following values:\n",
    "    a) positive float -> 'positive'\n",
    "    b) 0.0 -> 'neutral'\n",
    "    c) negative float -> 'negative'\n",
    "    \n",
    "    :param dict vader_output: output dict from vader\n",
    "    \n",
    "    :rtype: str\n",
    "    :return: 'negative' | 'neutral' | 'positive'\n",
    "    \"\"\"\n",
    "    compound = vader_output['compound']\n",
    "    \n",
    "    if compound < 0:\n",
    "        return 'negative'\n",
    "    elif compound == 0.0:\n",
    "        return 'neutral'\n",
    "    elif compound > 0.0:\n",
    "        return 'positive'\n",
    "    \n",
    "assert vader_output_to_label( {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.0}) == 'neutral'\n",
    "assert vader_output_to_label( {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.01}) == 'positive'\n",
    "assert vader_output_to_label( {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': -0.01}) == 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import nltk\n",
    "from nltk.sentiment import vader\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "import pathlib\n",
    "import sklearn\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "vader_model = SentimentIntensityAnalyzer()\n",
    "\n",
    "def run_vader(textual_unit, \n",
    "              lemmatize=False, \n",
    "              parts_of_speech_to_consider=None,\n",
    "              verbose=1):\n",
    "    \"\"\"\n",
    "    Run VADER on a sentence from spacy\n",
    "    \n",
    "    :param str textual unit: a textual unit, e.g., sentence, sentences (one string)\n",
    "    (by looping over doc.sents)\n",
    "    :param bool lemmatize: If True, provide lemmas to VADER instead of words\n",
    "    :param set parts_of_speech_to_consider:\n",
    "    -None or empty set: all parts of speech are provided\n",
    "    -non-empty set: only these parts of speech are considered.\n",
    "    :param int verbose: if set to 1, information is printed\n",
    "    about input and output\n",
    "    \n",
    "    :rtype: dict\n",
    "    :return: vader output dict\n",
    "    \"\"\"\n",
    "    doc = nlp(textual_unit)\n",
    "        \n",
    "    input_to_vader = []\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        for token in sent:\n",
    "\n",
    "            to_add = token.text\n",
    "\n",
    "            if lemmatize:\n",
    "                to_add = token.lemma_\n",
    "\n",
    "                if to_add == '-PRON-': \n",
    "                    to_add = token.text\n",
    "\n",
    "            if parts_of_speech_to_consider:\n",
    "                if token.pos_ in parts_of_speech_to_consider:\n",
    "                    input_to_vader.append(to_add) \n",
    "            else:\n",
    "                input_to_vader.append(to_add)\n",
    "\n",
    "    scores = vader_model.polarity_scores(' '.join(input_to_vader))\n",
    "    \n",
    "    if verbose >= 1:\n",
    "        print()\n",
    "        print('INPUT SENTENCE', sent)\n",
    "        print('INPUT TO VADER', input_to_vader)\n",
    "        print('VADER OUTPUT', scores)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INPUT SENTENCE _ricardo road movies indies rule  haha\n",
      "INPUT TO VADER ['_', 'ricardo', 'road', 'movie', 'indie', 'rule', ' ', 'haha']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 0.625, 'pos': 0.375, 'compound': 0.4588}\n",
      "\n",
      "INPUT SENTENCE just FYI.\n",
      "INPUT TO VADER [' ', 'p.s', '.', ':', 'uv', 'ray', 'be', 'just', 'as', 'strong', 'with', 'cloud', 'as', 'with', 'regular', 'sun', ',', 'sometimes', 'strong', '.', 'just', 'FYI', '.']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 0.605, 'pos': 0.395, 'compound': 0.8455}\n",
      "\n",
      "INPUT SENTENCE _jackson already there`s none left  back to cabbage soup\n",
      "INPUT TO VADER ['_', 'jackson', 'already', 'there`s', 'none', 'leave', ' ', 'back', 'to', 'cabbage', 'soup']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 0.875, 'pos': 0.125, 'compound': 0.0382}\n",
      "\n",
      "INPUT SENTENCE  The rest of the week is less than 2.5 hours long\n",
      "INPUT TO VADER [' ', 'the', 'rest', 'of', 'the', 'week', 'be', 'less', 'than', '2.5', 'hour', 'long']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\n",
      "INPUT SENTENCE I just woke up.\n",
      "INPUT TO VADER ['damnation', '.', 'I', 'just', 'wake', 'up', '.']\n",
      "VADER OUTPUT {'neg': 0.545, 'neu': 0.455, 'pos': 0.0, 'compound': -0.5574}\n",
      "\n",
      "INPUT SENTENCE here not  i think we`re dangerous (?\n",
      "INPUT TO VADER [' ', 'http://twitpic.com/5rylt', '-', 'ur', 'so', 'lucky', '!', 'there', ',', 'the', 'stage', 'its', 'so', 'close', 'of', 'theem', '!', 'here', 'not', ' ', 'I', 'think', 'we`re', 'dangerous', '(', '?']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 0.69, 'pos': 0.31, 'compound': 0.7753}\n",
      "\n",
      "INPUT SENTENCE Nuggets better pull it off tonight.\n",
      "INPUT TO VADER ['Friday', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', 'wooo', 'and', 'nothing', 'to', 'do', '.', ' ', 'nugget', 'well', 'pull', 'it', 'off', 'tonight', '.']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 0.771, 'pos': 0.229, 'compound': 0.5053}\n",
      "\n",
      "INPUT SENTENCE Boo.\n",
      "INPUT TO VADER ['need', 'some', 'snuggle', 'time', '....', ' ', 'but', 'have', 'to', 'get', 'through', 'the', 'work', 'day', 'first', '.', ' ', 'Boo', '.']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\n",
      "INPUT SENTENCE But it was worth it\n",
      "INPUT TO VADER ['home', 'from', 'Whitney`s', '.', 'no', 'sleep', '.', 'church', 'in', 'a', 'bit', '.', 'Dangggg', '....', 'I`m', 'tired', '.', 'but', 'it', 'be', 'worth', 'it']\n",
      "VADER OUTPUT {'neg': 0.178, 'neu': 0.704, 'pos': 0.118, 'compound': -0.0516}\n",
      "\n",
      "INPUT SENTENCE ::static::\n",
      "INPUT TO VADER ['_', 'in_fork', ':', ':', 'static', ':', ':', 'I', 'know', '!', 'i`ve', 'barely', 'see', 'anyone', 'since', 'I', 'get', 'into', 'Paris', 'yesterday', '.', ' ', 'i`ve', 'just', 'be', 'walk', 'around', '.', ' ', ':', ':', 'static', ':', ':']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\n",
      "INPUT SENTENCE I forgot I moved 100 east...make that 8 hours home.\n",
      "INPUT TO VADER ['I', 'forgot', 'I', 'move', '100', 'east', '...', 'make', 'that', '8', 'hour', 'home', '.']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\n",
      "INPUT SENTENCE now\n",
      "INPUT TO VADER [' ', 'Bandung', ',', 'my', 'hehe', 'but', 'I`m', 'home', 'now']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\n",
      "INPUT SENTENCE Yeah, but it`s Myst!\n",
      "INPUT TO VADER ['_', 'uk', 'Yeah', ',', 'but', 'it`s', 'Myst', '!']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 0.679, 'pos': 0.321, 'compound': 0.2244}\n",
      "\n",
      "INPUT SENTENCE  Munch away, my dear Watson, Munch away\n",
      "INPUT TO VADER [' ', 'Munch', 'away', ',', 'my', 'dear', 'Watson', ',', 'Munch', 'away']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 0.698, 'pos': 0.302, 'compound': 0.3818}\n",
      "\n",
      "INPUT SENTENCE My name is toggling in and out of Google Suggestions Help me by searching more for 'Ganesh Jaju' and clicking on some link\n",
      "INPUT TO VADER ['my', 'name', 'be', 'toggle', 'in', 'and', 'out', 'of', 'Google', 'Suggestions', 'help', 'I', 'by', 'search', 'more', 'for', \"'\", 'Ganesh', 'Jaju', \"'\", 'and', 'click', 'on', 'some', 'link']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 0.886, 'pos': 0.114, 'compound': 0.4019}\n",
      "\n",
      "INPUT SENTENCE directing a theatre play\n",
      "INPUT TO VADER ['direct', 'a', 'theatre', 'play']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 0.455, 'pos': 0.545, 'compound': 0.34}\n",
      "\n",
      "INPUT SENTENCE mondayyyyyy\n",
      "INPUT TO VADER ['mondayyyyyy']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\n",
      "INPUT SENTENCE @xzashley I miss you.\n",
      "INPUT TO VADER ['@xzashley', 'I', 'miss', 'you', '.']\n",
      "VADER OUTPUT {'neg': 0.444, 'neu': 0.556, 'pos': 0.0, 'compound': -0.1531}\n",
      "\n",
      "INPUT SENTENCE (via @umkaya) - I'm heartbroken too.\n",
      "INPUT TO VADER ['I', 'be', 'heartbroken', 'over', 'George', 'Tiller', '.', 'he', 'be', 'murderere', 'in', 'a', 'church', 'today', '.', '(', 'via', '@umkaya', ')', '-', 'I', 'be', 'heartbroken', 'too', '.']\n",
      "VADER OUTPUT {'neg': 0.381, 'neu': 0.619, 'pos': 0.0, 'compound': -0.8625}\n",
      "\n",
      "INPUT SENTENCE and couldnt go back to sleep\n",
      "INPUT TO VADER ['@theshoegirl', 'not', 'lame', 'at', 'all', 'I', 'be', 'sooo', 'scared', '!', 'and', 'could', 'not', 'go', 'back', 'to', 'sleep']\n",
      "VADER OUTPUT {'neg': 0.172, 'neu': 0.702, 'pos': 0.126, 'compound': -0.2168}\n",
      "\n",
      "INPUT SENTENCE was just on the phone to @Veganmercedes - i'm too poor to hang out today\n",
      "INPUT TO VADER ['be', 'just', 'on', 'the', 'phone', 'to', '@Veganmercedes', '-', 'I', 'be', 'too', 'poor', 'to', 'hang', 'out', 'today']\n",
      "VADER OUTPUT {'neg': 0.193, 'neu': 0.807, 'pos': 0.0, 'compound': -0.4767}\n",
      "\n",
      "INPUT SENTENCE I'm going to miss that silly girl\n",
      "INPUT TO VADER ['wonder', 'if', 'I', 'will', 'get', 'to', 'see', '@burchama', 'tonight', 'before', 'she', 'leave', 'town', 'tomorrow', '.', 'I', 'be', 'go', 'to', 'miss', 'that', 'silly', 'girl']\n",
      "VADER OUTPUT {'neg': 0.134, 'neu': 0.813, 'pos': 0.053, 'compound': -0.1779}\n",
      "\n",
      "INPUT SENTENCE way tired, prac report still to gooo\n",
      "INPUT TO VADER ['way', 'tired', ',', 'prac', 'report', 'still', 'to', 'gooo']\n",
      "VADER OUTPUT {'neg': 0.326, 'neu': 0.674, 'pos': 0.0, 'compound': -0.4404}\n",
      "\n",
      "INPUT SENTENCE I really want to like Morningwood, but they provided the theme song for &quot;Daisy of Love&quot; which is almost unforgivable in my book!\n",
      "INPUT TO VADER ['I', 'really', 'want', 'to', 'like', 'Morningwood', ',', 'but', 'they', 'provide', 'the', 'theme', 'song', 'for', '&', 'quot;Daisy', 'of', 'Love&quot', ';', 'which', 'be', 'almost', 'unforgivable', 'in', 'my', 'book', '!']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 0.852, 'pos': 0.148, 'compound': 0.3549}\n",
      "\n",
      "INPUT SENTENCE You look gorg in the photos, wish I could have been there to party with you  love u xx\n",
      "INPUT TO VADER ['@Fran_White', 'FRANNNNNNNNNY', 'how', 'be', 'your', 'birthday', '?', '?', 'you', 'look', 'gorg', 'in', 'the', 'photo', ',', 'wish', 'I', 'could', 'have', 'be', 'there', 'to', 'party', 'with', 'you', ' ', 'love', 'u', 'xx']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 0.668, 'pos': 0.332, 'compound': 0.8738}\n",
      "\n",
      "INPUT SENTENCE I got yelled at for rapping\n",
      "INPUT TO VADER ['I', 'get', 'yell', 'at', 'for', 'rap']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\n",
      "INPUT SENTENCE Went out for awhile this am, but saw nothing to inspire\n",
      "INPUT TO VADER ['go', 'out', 'for', 'awhile', 'this', 'am', ',', 'but', 'see', 'nothing', 'to', 'inspire']\n",
      "VADER OUTPUT {'neg': 0.286, 'neu': 0.714, 'pos': 0.0, 'compound': -0.612}\n",
      "\n",
      "INPUT SENTENCE so we only get a few FAM trips\n",
      "INPUT TO VADER ['@janetcavanagh', 'the', 'climb', 'wall', 'at', 'one', 'of', 'they', '.', 'good', 'article', '.', 'sperrin', 'be', 'not', 'high', 'on', 'the', 'NITB', 'agenda', 'so', 'we', 'only', 'get', 'a', 'few', 'FAM', 'trip']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 0.892, 'pos': 0.108, 'compound': 0.4404}\n",
      "\n",
      "INPUT SENTENCE also wish I could be at #biorama2 but found out about it too late\n",
      "INPUT TO VADER ['also', 'wish', 'I', 'could', 'be', 'at', '#', 'biorama2', 'but', 'find', 'out', 'about', 'it', 'too', 'late']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 0.866, 'pos': 0.134, 'compound': 0.2144}\n",
      "\n",
      "INPUT SENTENCE And the throw up tasted like Tobasco\n",
      "INPUT TO VADER ['@ravenalexis', 'when', 'I', 'watch', 'Titanic', ',', 'I', 'cry', 'so', 'hard', 'I', 'throw', 'up', '.', 'and', 'the', 'throw', 'up', 'taste', 'like', 'Tobasco']\n",
      "VADER OUTPUT {'neg': 0.243, 'neu': 0.635, 'pos': 0.122, 'compound': -0.3541}\n",
      "\n",
      "INPUT SENTENCE it's so hot\n",
      "INPUT TO VADER ['it', 'be', 'so', 'hot']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\n",
      "INPUT SENTENCE Diet cokes bad enough...diet rola cola is just shocking\n",
      "INPUT TO VADER ['diet', 'coke', 'bad', 'enough', '...', 'diet', 'rola', 'cola', 'be', 'just', 'shocking']\n",
      "VADER OUTPUT {'neg': 0.408, 'neu': 0.592, 'pos': 0.0, 'compound': -0.7351}\n",
      "\n",
      "INPUT SENTENCE Mom won't share her Krystal with me\n",
      "INPUT TO VADER ['mom', 'will', 'not', 'share', 'she', 'Krystal', 'with', 'I']\n",
      "VADER OUTPUT {'neg': 0.239, 'neu': 0.761, 'pos': 0.0, 'compound': -0.2235}\n",
      "\n",
      "INPUT SENTENCE @RobynHumes whats the ATL number?\n",
      "INPUT TO VADER ['@robynhume', 'what', 's', 'the', 'ATL', 'number', '?']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 0.755, 'pos': 0.245, 'compound': 0.0772}\n",
      "\n",
      "INPUT SENTENCE What a fun ...\n",
      "INPUT TO VADER ['finish', 'with', '#', 'Speedminton', 'for', 'today', '.', 'what', 'a', 'fun', '...']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 0.68, 'pos': 0.32, 'compound': 0.5106}\n",
      "\n",
      "INPUT SENTENCE im happy w my currnt phone  tp ol pke hp lmyn lbih cpet\n",
      "INPUT TO VADER ['@omania', 'emoh', 'bb', '.', 'I', 'm', 'happy', 'w', 'my', 'currnt', 'phone', ' ', 'tp', 'ol', 'pke', 'hp', 'lmyn', 'lbih', 'cpet']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 0.778, 'pos': 0.222, 'compound': 0.5719}\n",
      "\n",
      "INPUT SENTENCE PurchLive solves that problem at the right place and the right time\n",
      "INPUT TO VADER ['@jbillingsley', 'great', 'idea', ',', 'but', 'why', 'wait', 'until', 'the', 'cart', '?', ' ', 'PurchLive', 'solve', 'that', 'problem', 'at', 'the', 'right', 'place', 'and', 'the', 'right', 'time']\n",
      "VADER OUTPUT {'neg': 0.135, 'neu': 0.684, 'pos': 0.181, 'compound': 0.0516}\n",
      "\n",
      "INPUT SENTENCE Found dinner, woohoo!  - at Veritable Quandary http://shz.me/6DH\n",
      "INPUT TO VADER ['find', 'dinner', ',', 'woohoo', '!', ' ', '-', 'at', 'Veritable', 'Quandary', 'http://shz.me/6dh']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 0.626, 'pos': 0.374, 'compound': 0.5562}\n",
      "\n",
      "INPUT SENTENCE Named my new kitty Zeus\n",
      "INPUT TO VADER ['name', 'my', 'new', 'kitty', 'Zeus']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\n",
      "INPUT SENTENCE i still lurve my good ol' modded versions of sims 2.\n",
      "INPUT TO VADER ['sim', '3', 'be', 'not', 'that', 'great', '.', 'I', 'still', 'lurve', 'my', 'good', 'old', 'modded', 'version', 'of', 'sim', '2', '.']\n",
      "VADER OUTPUT {'neg': 0.181, 'neu': 0.66, 'pos': 0.159, 'compound': -0.1012}\n",
      "\n",
      "INPUT SENTENCE I have cousins in Australia too\n",
      "INPUT TO VADER ['@_janet', '_', 'Woo', '!', 'I', 'have', 'cousin', 'in', 'Australia', 'too']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 0.639, 'pos': 0.361, 'compound': 0.5255}\n",
      "\n",
      "INPUT SENTENCE nice video.\n",
      "INPUT TO VADER ['@speakifyplug', 'hey', ',', 'thank', '.', ')', 'I', 'subscribe', 'already', '.', 'nice', 'video', '.']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 0.485, 'pos': 0.515, 'compound': 0.6486}\n",
      "\n",
      "INPUT SENTENCE @MrsJasperHale08 Did you know he was born in San Antonio?!\n",
      "INPUT TO VADER ['@mrsjasperhale08', 'do', 'you', 'know', 'he', 'be', 'bear', 'in', 'San', 'Antonio', '?', '!']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\n",
      "INPUT SENTENCE Last day of school - enough said!\n",
      "INPUT TO VADER ['last', 'day', 'of', 'school', '-', 'enough', 'say', '!']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\n",
      "INPUT SENTENCE image of some of the Twitter tools and where they fit in the world: http://bit.ly/dUaco - www.MyTwitterButler.com not listed....yet\n",
      "INPUT TO VADER ['image', 'of', 'some', 'of', 'the', 'Twitter', 'tool', 'and', 'where', 'they', 'fit', 'in', 'the', 'world', ':', 'http://bit.ly/dUaco', '-', 'www.MyTwitterButler.com', 'not', 'list', '....', 'yet']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 0.884, 'pos': 0.116, 'compound': 0.3612}\n",
      "\n",
      "INPUT SENTENCE Honesty is never the best policy\n",
      "INPUT TO VADER ['Honesty', 'be', 'never', 'the', 'good', 'policy']\n",
      "VADER OUTPUT {'neg': 0.25, 'neu': 0.416, 'pos': 0.333, 'compound': 0.2008}\n",
      "\n",
      "INPUT SENTENCE Would be lost without mine (finger fiddler here)\n",
      "INPUT TO VADER ['@sarahnewton', ' ', 'yay', ' ', 'no', 'doubt', 'a', 'relief', '!', ' ', 'would', 'be', 'lose', 'without', 'mine', '(', 'finger', 'fiddler', 'here', ')']\n",
      "VADER OUTPUT {'neg': 0.347, 'neu': 0.36, 'pos': 0.293, 'compound': 0.1007}\n",
      "\n",
      "INPUT SENTENCE @ChefVanda You're very welcome\n",
      "INPUT TO VADER ['@chefvanda', 'you', 'be', 'very', 'welcome']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 0.548, 'pos': 0.452, 'compound': 0.5095}\n",
      "\n",
      "INPUT SENTENCE and I think they're really dating..\n",
      "INPUT TO VADER ['TEMI', '=', 'Trace+Demi', '...', 'hahaha', 'I', 'luv', 'this', 'couple', '..', 'and', 'I', 'think', 'they', 'be', 'really', 'date', '..']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 0.795, 'pos': 0.205, 'compound': 0.5574}\n",
      "\n",
      "INPUT SENTENCE What an eventful day\n",
      "INPUT TO VADER ['what', 'an', 'eventful', 'day']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "Classification Report (VADER Predictions vs. Gold Labels):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.59      0.67        17\n",
      "     neutral       0.42      0.31      0.36        16\n",
      "    positive       0.48      0.71      0.57        17\n",
      "\n",
      "    accuracy                           0.54        50\n",
      "   macro avg       0.56      0.54      0.53        50\n",
      "weighted avg       0.56      0.54      0.54        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "tweets = []\n",
    "all_vader_output = []\n",
    "gold = []\n",
    "\n",
    "# settings (to change for different experiments)\n",
    "to_lemmatize = True \n",
    "pos = set()\n",
    "\n",
    "for id_, tweet_info in my_tweets.items():\n",
    "    the_tweet = tweet_info['text_of_tweet']\n",
    "    vader_output = run_vader(the_tweet, to_lemmatize,verbose= 1)# run vader\n",
    "    vader_label = vader_output_to_label(vader_output)# convert vader output to category\n",
    "    \n",
    "    tweets.append(the_tweet)\n",
    "    all_vader_output.append(vader_label)\n",
    "    gold.append(tweet_info['sentiment_label'])\n",
    "    \n",
    "# use scikit-learn's classification report\n",
    "# Convert all gold labels to lowercase\n",
    "gold = [label.lower() for label in gold]\n",
    "\n",
    "all_vader_output = [label.lower() for label in all_vader_output]\n",
    "\n",
    "report = classification_report(gold, all_vader_output)\n",
    "\n",
    "print(\"Classification Report (VADER Predictions vs. Gold Labels):\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.a\n",
    "Well the results for neutral tweets are low, that could be due neutral being ambiguous for VADER. However, the F1 score is a good way of measuring the overall performance of VADER. VADER performed best on its negative tweets, as seen by the 0.67 F1 score, however it made a lot of mistakes, as the average f1 score is close to 0.5.\n",
    "\n",
    "## Question 3.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False-Negative for Neutral Tweets\n",
    "- 1. _ricardo road movies indies rule haha\n",
    "    - Predicted as: Positive.\n",
    "    - “haha” is a positive indicator in VADER’s lexicon. \n",
    "- 2. p.s.: UV rays are just as strong with clouds... just FYI.\n",
    "    - Positive\n",
    "    - \"strong\" has a positive valence for VADER\n",
    "\n",
    "- 3. _jackson already there’s none left back to cabbage soup\n",
    "    - Positive\n",
    "    - Maybe due to the already? or there was a mix of positive and negative words.\n",
    "\n",
    "- 4. Damnation. I just woke up.\n",
    "    - Negative\n",
    "    - \"Damnation\" has strong negative valence\n",
    " \n",
    "- 5. ...so lucky!...i think we're dangerous(?\n",
    "    - Positive\n",
    "    - \"lucky\" was the main cause, which overshadowed \"dangerous\"\n",
    " \n",
    "- 6. Friday!!!!!!!!!! Wooo and nothing to do... Nuggets better pull it off\n",
    "    - Positive\n",
    "    - In context it makes sense, but VADER picks up \"Friday\", \"!\" and \"Woo\" with positive valence\n",
    "\n",
    "- 7. Home from Whitney`s. No sleep. Church in a bit. Dangggg....I`m tired. But it was worth it\"\n",
    "    - Negative\n",
    "    - \"Dang\" \"No\" and \"tired\" probably caused the negative result\n",
    "\n",
    "- 8. _uk Yeah, but it’s Myst!\n",
    "    - Positive\n",
    "    - \"Yeah\" is a positive valence word.\n",
    "\n",
    "- 9. Munch away, my dear Watson, Munch away\n",
    "    - Positive\n",
    "    - Possibly due to \"dear\"?\n",
    "\n",
    "- 10. My name is toggling in and out of Google Suggestions Help me by searching more for 'Ganesh Jaju' and clicking on some link\n",
    "    - Positive\n",
    "    - Unknown why it would treat this as positive.\n",
    "\n",
    "\n",
    "## False-Negative for Negative Tweets\n",
    "\n",
    "- 1. mondayyyyyy\n",
    "  - Neutral\n",
    "  - VADER sees “mondayyyyyy” as a neutral word\n",
    "\n",
    "- 2. I really want to like Morningwood, but they provided the theme song for &quot;Daisy of Love&quot; which is almost unforgivable in my book!\n",
    "  - Positive\n",
    "  - \"want to like\", \"really\", \"Love\" are all positive valence words.\n",
    "\n",
    "- 3. FRANNNNNNNNNY how was your birthday?? You look gorg in the photos, wish I could have been there to party with you  love u xx\n",
    "  - Positive\n",
    "  - Actually this one is a mistake of where i recieved the tweets from. So VADER correctly predicted positive here.\n",
    "\n",
    "- 4. I got yelled at for rapping\n",
    "  - Neutral\n",
    "  - \"yelled at\" maybe did not produce much of a negative valence\n",
    "\n",
    "- 5. the climbing wall at one of them. Good article. Sperrins aren't high on the NITB agenda so we only get a few FAM trips \n",
    "  - Positive\n",
    "  - \"good article\" could lead to positive result\n",
    "\n",
    "- 6. also wish I could be at #biorama2 but found out... too late\n",
    "  - Positive\n",
    "  - \"wish\" could be a strong positive valence\n",
    "\n",
    "- 7. it's so hot\n",
    "  - Neutral\n",
    "  - \"hot\" is not necessarily negative for VADER\n",
    "\n",
    "\n",
    "### False-Negatives for Positive Tweets\n",
    "\n",
    "- 1. Named my new kitty Zeus\n",
    "  - Neutral\n",
    "  - \"kitty\" is treated as neutral, \"new\" also.\n",
    "\n",
    "- 2. sims 3 isnt that great. i still lurve my good ol' modded versions of sims 2.\n",
    "  - Negative\n",
    "  - \"isn't great\" definitely, and also the incorrect grammar on \"lurve\" meaning VANDER possibly did not recognise the word love\n",
    "\n",
    "- 3. Did you know he was born in San Antonio?!\n",
    "  - Neutral\n",
    "  - The \"?!\" made it neutral.\n",
    "\n",
    "- 4. Last day of school - enough said\n",
    "  - Neutral\n",
    "  - VANDER does not understand context, and no positive words were used.\n",
    "\n",
    "- 5. What an eventful day\n",
    "  - Neutral\n",
    "  - \"eventful\" recognised as a neutral word\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4 points] Question 4:\n",
    "Run VADER on the set of airline tweets with the following settings:\n",
    "\n",
    "* Run VADER (as it is) on the set of airline tweets \n",
    "* Run VADER on the set of airline tweets after having lemmatized the text\n",
    "* Run VADER on the set of airline tweets with only adjectives\n",
    "* Run VADER on the set of airline tweets with only adjectives and after having lemmatized the text\n",
    "* Run VADER on the set of airline tweets with only nouns\n",
    "* Run VADER on the set of airline tweets with only nouns and after having lemmatized the text\n",
    "* Run VADER on the set of airline tweets with only verbs\n",
    "* Run VADER on the set of airline tweets with only verbs and after having lemmatized the text\n",
    "\n",
    "* [1 point] a. Generate for all separate experiments the classification report, i.e., Precision, Recall, and F<sub>1</sub> scores per category as well as micro and macro averages. **Use a different code cell (or multiple code cells) for each experiment.**\n",
    "* [3 points] b. Compare the scores and explain what they tell you.\n",
    "* - Does lemmatisation help? Explain why or why not.\n",
    "* - Are all parts of speech equally important for sentiment analysis? Explain why or why not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Preliminaries\n",
    "cwd = pathlib.Path.cwd()\n",
    "airline_tweets_folder = cwd.joinpath('airlinetweets')\n",
    "path = str(airline_tweets_folder)\n",
    "\n",
    "airline_tweets = load_files(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# List to store all tweets with their sentiment\n",
    "all_airline_tweets = []\n",
    "\n",
    "# Iterate through each folder inside airlinetweets\n",
    "for folder_name in os.listdir(airline_tweets_folder):\n",
    "    folder_path = airline_tweets_folder / folder_name\n",
    "    if folder_path.is_dir():\n",
    "        # Iterate through each file in the current folder\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            file_path = folder_path / file_name\n",
    "            if file_path.is_file():\n",
    "                # Read the text from the file and add it to the list\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    tweet_text = file.read().strip()\n",
    "                    all_airline_tweets.append([folder_name, tweet_text])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_vader_on_airline_tweets(lemmatize=False, pos=None):\n",
    "    gold_airline = []\n",
    "    all_vader_output_airline = []\n",
    "    tweets_airline = []\n",
    "\n",
    "    for tweet in all_airline_tweets:\n",
    "        tweet_text = tweet[1]\n",
    "        vader_output_airline = run_vader(tweet_text, lemmatize, pos, verbose=0)\n",
    "        vader_label_airline = vader_output_to_label(vader_output_airline)\n",
    "\n",
    "        tweets_airline.append(tweet_text)\n",
    "        all_vader_output_airline.append(vader_label_airline)\n",
    "        gold_airline.append(tweet[0])\n",
    "\n",
    "    gold_airline = [label.lower() for label in gold_airline]\n",
    "    all_vader_output_airline = [label.lower() for label in all_vader_output_airline]\n",
    "\n",
    "    report_airline = classification_report(gold_airline, all_vader_output_airline)\n",
    "    return report_airline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airline Report : As-Is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.51      0.63      1750\n",
      "     neutral       0.60      0.51      0.55      1515\n",
      "    positive       0.56      0.88      0.68      1490\n",
      "\n",
      "    accuracy                           0.63      4755\n",
      "   macro avg       0.65      0.64      0.62      4755\n",
      "weighted avg       0.66      0.63      0.62      4755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# As-Is\n",
    "print(\"Airline Report : As-Is\")\n",
    "report_airline = run_vader_on_airline_tweets(lemmatize=False, pos=set())\n",
    "print(report_airline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airline Report : Lemmatized\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.52      0.63      1750\n",
      "     neutral       0.60      0.49      0.54      1515\n",
      "    positive       0.56      0.88      0.68      1490\n",
      "\n",
      "    accuracy                           0.62      4755\n",
      "   macro avg       0.65      0.63      0.62      4755\n",
      "weighted avg       0.65      0.62      0.62      4755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lemmatized\n",
    "print(\"Airline Report : Lemmatized\")\n",
    "report_airline_lemmatized = run_vader_on_airline_tweets(lemmatize=True, pos=set())\n",
    "print(report_airline_lemmatized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airline Report : As-Is with ADJ POS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.20      0.33      1750\n",
      "     neutral       0.40      0.89      0.55      1515\n",
      "    positive       0.67      0.44      0.53      1490\n",
      "\n",
      "    accuracy                           0.50      4755\n",
      "   macro avg       0.64      0.51      0.47      4755\n",
      "weighted avg       0.65      0.50      0.46      4755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# As-Is with only Adjectives\n",
    "print(\"Airline Report : As-Is with ADJ POS\")\n",
    "report_airline_adj = run_vader_on_airline_tweets(lemmatize=False, pos={'ADJ'})\n",
    "print(report_airline_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airline Report : Lemmatized with ADJ POS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.20      0.33      1750\n",
      "     neutral       0.40      0.89      0.55      1515\n",
      "    positive       0.67      0.44      0.53      1490\n",
      "\n",
      "    accuracy                           0.50      4755\n",
      "   macro avg       0.64      0.51      0.47      4755\n",
      "weighted avg       0.65      0.50      0.46      4755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lemmatized with only Adjectives\n",
    "print(\"Airline Report : Lemmatized with ADJ POS\")\n",
    "report_airline_lemmatized_adj = run_vader_on_airline_tweets(lemmatize=True, pos={'ADJ'})\n",
    "print(report_airline_lemmatized_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airline Report : As-Is with NOUN POS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.14      0.23      1750\n",
      "     neutral       0.36      0.82      0.50      1515\n",
      "    positive       0.53      0.35      0.42      1490\n",
      "\n",
      "    accuracy                           0.42      4755\n",
      "   macro avg       0.54      0.44      0.39      4755\n",
      "weighted avg       0.55      0.42      0.38      4755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# As-Is with only Nouns\n",
    "print(\"Airline Report : As-Is with NOUN POS\")\n",
    "report_airline_noun = run_vader_on_airline_tweets(lemmatize=False, pos={'NOUN'})\n",
    "print(report_airline_noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airline Report : Lemmatized with NOUN POS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.15      0.25      1750\n",
      "     neutral       0.36      0.81      0.50      1515\n",
      "    positive       0.52      0.34      0.41      1490\n",
      "\n",
      "    accuracy                           0.42      4755\n",
      "   macro avg       0.53      0.44      0.39      4755\n",
      "weighted avg       0.54      0.42      0.38      4755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lemmatized with only Nouns\n",
    "print(\"Airline Report : Lemmatized with NOUN POS\")\n",
    "report_airline_lemmatized_noun = run_vader_on_airline_tweets(lemmatize=True, pos={'NOUN'})\n",
    "print(report_airline_lemmatized_noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airline Report : As-Is with VERB POS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.29      0.42      1750\n",
      "     neutral       0.38      0.81      0.52      1515\n",
      "    positive       0.57      0.35      0.43      1490\n",
      "\n",
      "    accuracy                           0.47      4755\n",
      "   macro avg       0.58      0.48      0.46      4755\n",
      "weighted avg       0.59      0.47      0.46      4755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# As-Is with only Verbs\n",
    "print(\"Airline Report : As-Is with VERB POS\")\n",
    "report_airline_verb = run_vader_on_airline_tweets(lemmatize=False, pos={'VERB'})\n",
    "print(report_airline_verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airline Report : Lemmatized with VERB POS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.29      0.42      1750\n",
      "     neutral       0.38      0.78      0.51      1515\n",
      "    positive       0.57      0.36      0.44      1490\n",
      "\n",
      "    accuracy                           0.47      4755\n",
      "   macro avg       0.57      0.48      0.46      4755\n",
      "weighted avg       0.58      0.47      0.46      4755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lemmatized with only Verbs\n",
    "print(\"Airline Report : Lemmatized with VERB POS\")\n",
    "report_airline_lemmatized_verb = run_vader_on_airline_tweets(lemmatize=True, pos={'VERB'})\n",
    "print(report_airline_lemmatized_verb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4b\n",
    "\n",
    "When VADER is run As-Is, it has the best performance, with an accuracy of 0.63, meanwhile the Lemmatized result ends up being just slightly worse at 0.62, but it is not significant enough to make a noticeable difference. In this case, Lemmatization does not help. The reason could be that VADER does not recognise some Lemmatized words. Anywhere else, Lemmatization and As-Is does not have any difference at all.\n",
    "\n",
    "Meanwhile, when using Parts-Of-Speech to measure sentiment analysis. We notice that adjectives have a slightly higher accuracy (0.50), with verbs coming second (0.47) and nouns having an accuracy of 0.42. This could mean that Adjectives are slightly more helpful at analysing sentiment, with verbs having a slightly less impactful (but still impactful) result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: scikit-learn assignments\n",
    "### [4 points] Question 5\n",
    "Train the scikit-learn classifier (Naive Bayes) using the airline tweets.\n",
    "\n",
    "+ Train the model on the airline tweets with 80% training and 20% test set and default settings (TF-IDF representation, min_df=2)\n",
    "+ Train with different settings:\n",
    "    + with respect to vectorizing: TF-IDF ('airline_tfidf') vs. Bag of words representation ('airline_count') \n",
    "    + with respect to the frequency threshold (min_df). Carry out experiments with increasing values for document frequency (min_df = 2; min_df = 5; min_df =10) \n",
    "* [1 point] a. Generate a classification_report for all experiments\n",
    "* [3 points] b. Look at the results of the experiments with the different settings and try to explain why they differ: \n",
    "    + which category performs best, is this the case for any setting?\n",
    "    + does the frequency threshold affect the scores? Why or why not according to you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4 points] Question 6: Inspecting the best scoring features \n",
    "\n",
    "+ Train the scikit-learn classifier (Naive Bayes) model with the following settings (airline tweets 80% training and 20% test;  Bag of words representation ('airline_count'), min_df=2)\n",
    "* [1 point] a. Generate the list of best scoring features per class (see function **important_features_per_class** below) [1 point]\n",
    "* [3 points] b. Look at the lists and consider the following issues: \n",
    "    + [1 point] Which features did you expect for each separate class and why?\n",
    "    + [1 point] Which features did you not expect and why ? \n",
    "    + [1 point] The list contains all kinds of words such as names of airlines, punctuation, numbers and content words (e.g., 'delay' and 'bad'). Which words would you remove or keep when trying to improve the model and why? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def important_features_per_class(vectorizer,classifier,n=80):\n",
    "    class_labels = classifier.classes_\n",
    "    feature_names =vectorizer.get_feature_names()\n",
    "    topn_class1 = sorted(zip(classifier.feature_count_[0], feature_names),reverse=True)[:n]\n",
    "    topn_class2 = sorted(zip(classifier.feature_count_[1], feature_names),reverse=True)[:n]\n",
    "    topn_class3 = sorted(zip(classifier.feature_count_[2], feature_names),reverse=True)[:n]\n",
    "    print(\"Important words in negative documents\")\n",
    "    for coef, feat in topn_class1:\n",
    "        print(class_labels[0], coef, feat)\n",
    "    print(\"-----------------------------------------\")\n",
    "    print(\"Important words in neutral documents\")\n",
    "    for coef, feat in topn_class2:\n",
    "        print(class_labels[1], coef, feat) \n",
    "    print(\"-----------------------------------------\")\n",
    "    print(\"Important words in positive documents\")\n",
    "    for coef, feat in topn_class3:\n",
    "        print(class_labels[2], coef, feat) \n",
    "\n",
    "# example of how to call from notebook:\n",
    "#important_features_per_class(airline_vec, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional! (will not  be graded)] Question 7\n",
    "Train the model on airline tweets and test it on your own set of tweets\n",
    "+ Train the model with the following settings (airline tweets 80% training and 20% test;  Bag of words representation ('airline_count'), min_df=2)\n",
    "+ Apply the model on your own set of tweets and generate the classification report\n",
    "* [1 point] a. Carry out a quantitative analysis.\n",
    "* [1 point] b. Carry out an error analysis on 10 correctly and 10 incorrectly classified tweets and discuss them\n",
    "* [2 points] c. Compare the results (cf. classification report) with the results obtained by VADER on the same tweets and discuss the differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional! (will not be graded)] Question 8: trying to improve the model\n",
    "* [2 points] a. Think of some ways to improve the scikit-learn Naive Bayes model by playing with the settings or applying linguistic preprocessing (e.g., by filtering on part-of-speech, or removing punctuation). Do not change the classifier but continue using the Naive Bayes classifier. Explain what the effects might be of these other settings \n",
    "+ [1 point] b. Apply the model with at least one new setting (train on the airline tweets using 80% training, 20% test) and generate the scores\n",
    "* [1 point] c. Discuss whether the model achieved what you expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TextMining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
